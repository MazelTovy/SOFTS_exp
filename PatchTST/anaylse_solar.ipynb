{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f40439",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def load_config(yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return SimpleNamespace(**config)\n",
    "\n",
    "def find_model_files(directory, dataset_name):\n",
    "    \"\"\"\n",
    "    在指定目录下查找包含特定数据集名称的模型文件\n",
    "    \n",
    "    参数:\n",
    "        directory (str): 要搜索的目录路径\n",
    "        dataset_name (str): 要查找的数据集名称(如\"ETTh1\")\n",
    "    \n",
    "    返回:\n",
    "        list: 匹配的模型文件路径列表\n",
    "    \"\"\"\n",
    "    \n",
    "    # 遍历目录下的所有文件和子目录\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir in dirs:\n",
    "            # 检查文件名中是否包含数据集名称(不区分大小写)\n",
    "            if dataset_name.lower() in dir.lower():\n",
    "                # 构建完整文件路径\n",
    "                file_path = os.path.join(root, dir, \"checkpoint.pth\")\n",
    "                yaml_path = os.path.join(root, dir, \"config.yaml\")\n",
    "    \n",
    "    return file_path, yaml_path\n",
    "\n",
    "model_dir = \"/scratch/sx2490/SOFTS_exp/PatchTST/PatchTST_supervised/checkpoints/solar_48_48_PatchTST_Solar_ftM_sl48_ll48_pl48_dm512_nh8_el2_dl1_df512_fc1_ebtimeF_dtTrue_Exp_0\"\n",
    "dataset_name = \"solar\"\n",
    "model_path, yaml_path = find_model_files(model_dir, dataset_name)\n",
    "config = load_config(yaml_path)\n",
    "config.batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fe8084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "train 36625\n",
      "val 5137\n",
      "test 10393\n"
     ]
    }
   ],
   "source": [
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "\n",
    "exp = Exp_Long_Term_Forecast(config)\n",
    "train_data, train_loader = exp._get_data(flag='train')\n",
    "vali_data, vali_loader = exp._get_data(flag='val')\n",
    "test_data, test_loader = exp._get_data(flag='test')\n",
    "exp.model.load_state_dict(torch.load(model_path))\n",
    "model = exp.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b56b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1145it [02:29,  7.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.18180756, 0.15542659, 5.387772925764192)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "mask_len = 48\n",
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "train_loss = []\n",
    "train_loss_mask = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in tqdm(enumerate(train_loader)):\n",
    "        batch_x = batch_x.float().to(exp.device)\n",
    "        batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float().to(exp.device)\n",
    "\n",
    "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "        f_dim = -1 if exp.args.features == 'MS' else 0\n",
    "        outputs = outputs[:, -exp.args.pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -exp.args.pred_len:, f_dim:].to(exp.device)\n",
    "        loss = criterion(outputs, batch_y).mean(dim=[1, 2]).cpu()\n",
    "\n",
    "        loss_mask_floats = []\n",
    "        for i in range(mask_len):\n",
    "            batch_x_mask = batch_x.float().to(exp.device)\n",
    "            batch_x_mask[:, :i, :] = 0\n",
    "            outputs_mask = model(batch_x_mask, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            loss_mask = criterion(outputs_mask, batch_y).mean(dim=[1, 2]).cpu()\n",
    "            loss_mask_floats.append(loss_mask)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_mask_floats = torch.stack(loss_mask_floats).permute(1, 0)\n",
    "        min_loss_mask_float = loss_mask_floats.min(-1).values\n",
    "        diff = loss - min_loss_mask_float\n",
    "        count += torch.sum(diff > 0).item()\n",
    "\n",
    "\n",
    "        train_loss.extend(list(loss))\n",
    "        train_loss_mask.extend(list(min_loss_mask_float))\n",
    "\n",
    "np.average(train_loss), np.average(train_loss_mask), count / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbafc054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11797952218430034"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/ len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49573ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "325it [00:42,  7.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27882376, 0.1679863, 13.295384615384615)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "mask_len = 48\n",
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "train_loss = []\n",
    "train_loss_mask = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in tqdm(enumerate(test_loader)):\n",
    "        batch_x = batch_x.float().to(exp.device)\n",
    "        batch_y = batch_y.float().to(exp.device)\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float().to(exp.device)\n",
    "\n",
    "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "        f_dim = -1 if exp.args.features == 'MS' else 0\n",
    "        outputs = outputs[:, -exp.args.pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -exp.args.pred_len:, f_dim:].to(exp.device)\n",
    "        loss = criterion(outputs, batch_y).mean(dim=[1, 2]).cpu()\n",
    "\n",
    "        loss_mask_floats = []\n",
    "        for i in range(mask_len):\n",
    "            batch_x_mask = batch_x.float().to(exp.device)\n",
    "            batch_x_mask[:, :i, :] = 0\n",
    "            outputs_mask = model(batch_x_mask, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            loss_mask = criterion(outputs_mask, batch_y).mean(dim=[1, 2]).cpu()\n",
    "            loss_mask_floats.append(loss_mask)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_mask_floats = torch.stack(loss_mask_floats).permute(1, 0)\n",
    "        min_loss_mask_float = loss_mask_floats.min(-1).values\n",
    "        diff = loss - min_loss_mask_float\n",
    "        count += torch.sum(diff > 0).item()\n",
    "\n",
    "\n",
    "        train_loss.extend(list(loss))\n",
    "        train_loss_mask.extend(list(min_loss_mask_float))\n",
    "\n",
    "np.average(train_loss), np.average(train_loss_mask), count / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c150b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41576060810160687"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/ len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ed2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "我喜欢你",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
